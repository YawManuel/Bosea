{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13372148,
          "sourceType": "datasetVersion",
          "datasetId": 8483550
        },
        {
          "sourceId": 13372169,
          "sourceType": "datasetVersion",
          "datasetId": 8483563
        },
        {
          "sourceId": 13411562,
          "sourceType": "datasetVersion",
          "datasetId": 8511624
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Barbados Land Survey",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YawManuel/Bosea/blob/main/Barbados_Land_Survey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "nAYB6PTA_GWy"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "yawmanuel_barbados_path = kagglehub.dataset_download('yawmanuel/barbados')\n",
        "yawmanuel_barbados_testfile_path = kagglehub.dataset_download('yawmanuel/barbados-testfile')\n",
        "yawmanuel_survey_plans_path = kagglehub.dataset_download('yawmanuel/survey-plans')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "i-9SReti_GW0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle/Local Notebook: Land Survey Plot Extraction and Metadata Pipeline (Path-Fixed)\n",
        "# =====================================================================\n",
        "# Set BASE_DIR to your data root (e.g., '/kaggle/input/dataset/' or './data/').\n",
        "# Assumes: train.csv, test.csv, survey-images/ folder all in BASE_DIR.\n",
        "\n",
        "# Cell 1: Install Dependencies (Run once)\n",
        "import sys\n",
        "!{sys.executable} -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!{sys.executable} -m pip install opencv-python pytesseract geopandas shapely scikit-learn albumentations pandas numpy matplotlib seaborn detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.13/index.html\n",
        "!apt-get update && apt-get install -y tesseract-ocr  # For OCR; skip if local"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T08:29:53.155438Z",
          "iopub.execute_input": "2025-10-17T08:29:53.15617Z"
        },
        "id": "Dm8yxWOa_GW1",
        "outputId": "1ad3b4ce-9734-4e29-e989-e293302629cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Looking in indexes: https://download.pytorch.org/whl/cpu\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.0.1+cpu)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.15.2+cpu)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.0.2+cpu)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.2.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.32.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2025.8.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import pytesseract\n",
        "from shapely.wkt import loads\n",
        "from shapely.geometry import Polygon\n",
        "import geopandas as gpd\n",
        "from difflib import SequenceMatcher\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# PATH CONFIGURATION\n",
        "BASE_DIR = './'  # CHANGE THIS: e.g., '/kaggle/input/your-dataset/' or './'\n",
        "TRAIN_CSV = os.path.join(BASE_DIR, '/kaggle/input/barbados/Train.csv')\n",
        "TEST_CSV = os.path.join(BASE_DIR, '/kaggle/input/barbados-testfile/Test.csv')\n",
        "IMAGE_DIR = os.path.join(BASE_DIR, '/kaggle/input/survey-plans')  # Folder with {ID}.jpg\n",
        "\n",
        "print(f\"Train path: {TRAIN_CSV} (exists: {os.path.exists(TRAIN_CSV)})\")\n",
        "print(f\"Test path: {TEST_CSV} (exists: {os.path.exists(TEST_CSV)})\")\n",
        "print(f\"Images dir: {IMAGE_DIR} (exists: {os.path.exists(IMAGE_DIR)})\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "BlcV4i3h_GW3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Helper Functions (Unchanged from previous)\n",
        "def clean_target_survey(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[.,]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "def format_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df[\"TargetSurvey\"] = (\n",
        "        df[\"Land Surveyor\"].astype(str).str.strip() + \" \" +\n",
        "        df[\"Surveyed For\"].astype(str).str.strip() + \" \" +\n",
        "        df[\"Address\"].astype(str).str.strip()\n",
        "    ).apply(clean_target_survey)\n",
        "    columns_to_keep = ['ID', 'TargetSurvey', 'Certified date', 'Total Area', 'Unit of Measurement', 'Parish', 'LT Num', 'geometry']\n",
        "    return df[columns_to_keep]\n",
        "\n",
        "def polygon_to_mask(polygon, width=256, height=256):\n",
        "    if polygon is None or polygon.is_empty:\n",
        "        return np.zeros((height, width), dtype=np.uint8)\n",
        "    minx, miny, maxx, maxy = polygon.bounds\n",
        "    coords = np.array(polygon.exterior.coords)\n",
        "    x_scale = width / (maxx - minx) if maxx != minx else 1\n",
        "    y_scale = height / (maxy - miny) if maxy != miny else 1\n",
        "    pixel_coords = np.array([[(x - minx) * x_scale, (maxy - y) * y_scale] for x, y in coords], dtype=np.int32)\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "    cv2.fillPoly(mask, [pixel_coords], 1)\n",
        "    return mask\n",
        "\n",
        "def compute_iou(mask1, mask2):\n",
        "    intersection = np.logical_and(mask1, mask2).sum()\n",
        "    union = np.logical_or(mask1, mask2).sum()\n",
        "    return intersection / union if union > 0 else 0\n",
        "\n",
        "def wer(pred_text, gt_text):\n",
        "    return 1 - SequenceMatcher(None, pred_text, gt_text).ratio()\n",
        "\n",
        "def ocr_extract_metadata(image_path, id_key):\n",
        "    if not os.path.exists(image_path):\n",
        "        # Mock defaults if no image\n",
        "        return {'ID': id_key, 'Land Surveyor': 'Unknown', 'Surveyed For': 'Unknown',\n",
        "                'Certified date': 'Unknown', 'Total Area': 0.0, 'Unit of Measurement': 'sq m',\n",
        "                'Address': 'Unknown', 'Parish': 'St. Philip', 'LT Num': 'Unknown',\n",
        "                'geometry': 'POLYGON Z ((0 0 0, 0 0 0, 0 0 0, 0 0 0))'}\n",
        "\n",
        "    img = cv2.imread(image_path, 0)\n",
        "    if img is None:\n",
        "        return ocr_extract_metadata(image_path, id_key)  # Retry mock\n",
        "    img = cv2.medianBlur(img, 5)\n",
        "    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    text = pytesseract.image_to_string(img)\n",
        "\n",
        "    data = {'ID': id_key}\n",
        "    # Tuned regex (as before)\n",
        "    surveyor_match = re.search(r'(?:Land Surveyor|Surveyor)\\s*[:\\s]*(.+?)(?:\\n|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    data['Land Surveyor'] = surveyor_match.group(1).strip() if surveyor_match else 'Unknown'\n",
        "\n",
        "    surveyed_match = re.search(r'surveyed\\s+for\\s+(.+?)(?:\\n|$)', text, re.IGNORECASE | re.DOTALL)\n",
        "    data['Surveyed For'] = surveyed_match.group(1).strip() if surveyed_match else 'Unknown'\n",
        "\n",
        "    date_match = re.search(r'certified?\\s+(.+?)(?:\\d{4}|\\n)', text, re.IGNORECASE)\n",
        "    data['Certified date'] = date_match.group(1).strip() if date_match else 'Unknown'\n",
        "\n",
        "    area_match = re.search(r'total\\s*(?:area|land)\\s*[:\\s]*(\\d+(?:\\.\\d+)?)\\s*(sq\\s*m|sqm)', text, re.IGNORECASE)\n",
        "    data['Total Area'] = float(area_match.group(1)) if area_match else 0.0\n",
        "    data['Unit of Measurement'] = area_match.group(2).strip() if area_match else 'sq m'\n",
        "\n",
        "    address_match = re.search(r'lot\\s+\\d+\\s*,?\\s*(.+?)(?:,\\s*stage|\\n)', text, re.IGNORECASE | re.DOTALL)\n",
        "    data['Address'] = address_match.group(1).strip() if address_match else 'Unknown'\n",
        "\n",
        "    parish_match = re.search(r'st\\.\\s*philip', text, re.IGNORECASE)\n",
        "    data['Parish'] = parish_match.group(0).strip() if parish_match else 'St. Philip'\n",
        "\n",
        "    lt_match = re.search(r'(?:lt\\s+num|land\\s+tax\\s+ref|file\\s+no)[:\\s]*([^\\n]+)', text, re.IGNORECASE)\n",
        "    data['LT Num'] = lt_match.group(1).strip() if lt_match else 'Unknown'\n",
        "\n",
        "    # Polygon from contours\n",
        "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        largest = max(contours, key=cv2.contourArea)\n",
        "        epsilon = 0.02 * cv2.arcLength(largest, True)\n",
        "        approx = cv2.approxPolyDP(largest, epsilon, True)\n",
        "        if len(approx) >= 3:\n",
        "            coords = [(pt[0][0], pt[0][1]) for pt in approx]\n",
        "            wkt_coords = ', '.join([f'{x} {y} 0' for x, y in coords]) + ', 0 0 0'\n",
        "            data['geometry'] = f\"POLYGON Z (({wkt_coords}))\"\n",
        "        else:\n",
        "            data['geometry'] = 'POLYGON Z ((0 0 0, 0 0 0, 0 0 0, 0 0 0))'\n",
        "    else:\n",
        "        data['geometry'] = 'POLYGON Z ((0 0 0, 0 0 0, 0 0 0, 0 0 0))'\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "trusted": true,
        "id": "SBV7ebBr_GW4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load & Preprocess Train (for Model Training)\n",
        "df_train = pd.read_csv(TRAIN_CSV)\n",
        "extracted_train = []\n",
        "for idx, row in df_train.iterrows():\n",
        "    id_key = row['ID']\n",
        "    image_path = os.path.join(IMAGE_DIR, f\"{id_key}.jpg\")\n",
        "    extracted = ocr_extract_metadata(image_path, id_key)\n",
        "    # Merge with CSV (prioritize OCR)\n",
        "    for key in extracted:\n",
        "        if key != 'ID' and pd.isna(row.get(key, np.nan)):\n",
        "            row[key] = extracted[key]\n",
        "    extracted_train.append(row)\n",
        "df_train = pd.DataFrame(extracted_train)\n",
        "df_train = format_dataset(df_train)\n",
        "print(f\"Train DF: {df_train.shape}\")\n",
        "\n",
        "# Cell 5: EDA (Optional for Train)\n",
        "def eda(df):\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"Missing:\\n\", df.isnull().sum())\n",
        "    df['Total Area'].hist(bins=20)\n",
        "    plt.title('Total Area Dist')\n",
        "    plt.show()\n",
        "    df['polygon'] = df['geometry'].apply(lambda wkt: loads(wkt) if wkt else None)\n",
        "    print(\"Valid Geoms:\", df['polygon'].apply(lambda p: p.is_valid if p else False).mean())\n",
        "eda(df_train)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "jqCja7jz_GW5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Preprocess Train\n",
        "def preprocess_data(df):\n",
        "    df = df.dropna(subset=['Total Area', 'geometry'])\n",
        "    le_parish = LabelEncoder()\n",
        "    df['Parish Encoded'] = le_parish.fit_transform(df['Parish'])\n",
        "    scaler = StandardScaler()\n",
        "    df['Total Area Normalized'] = scaler.fit_transform(df[['Total Area']]).flatten()\n",
        "    df['polygon'] = df['geometry'].apply(lambda wkt: loads(wkt) if wkt else None)\n",
        "    df['computed_area'] = df['polygon'].apply(lambda p: p.area if p else 0)\n",
        "    df['perimeter'] = df['polygon'].apply(lambda p: p.length if p else 0)\n",
        "    df['centroid_x'] = df['polygon'].apply(lambda p: p.centroid.x if p else 0)\n",
        "    df['centroid_y'] = df['polygon'].apply(lambda p: p.centroid.y if p else 0)\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "    return train_df, val_df, test_df, scaler, le_parish\n",
        "\n",
        "train_df, val_df, test_df, scaler, le_parish = preprocess_data(df_train)\n",
        "\n",
        "# Cell 7: Datasets (Unchanged)\n",
        "class SurveyDataset(Dataset):\n",
        "    def __init__(self, df, features, image_dir=None):\n",
        "        self.df = df\n",
        "        self.features = df[features].values\n",
        "        self.labels = df['Total Area'].values\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feat = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        id_key = self.df.iloc[idx]['ID']\n",
        "        img_path = os.path.join(self.image_dir, f\"{id_key}.jpg\") if self.image_dir else None\n",
        "        if img_path and os.path.exists(img_path):\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            transform = A.Compose([A.Resize(224, 224), A.Normalize(), ToTensorV2()])\n",
        "            img = transform(image=img)['image']\n",
        "        else:\n",
        "            img = torch.zeros(3, 224, 224)\n",
        "        return {'features': feat, 'image': img, 'label': label}\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        features = torch.stack([item['features'] for item in batch])\n",
        "        images = torch.stack([item['image'] for item in batch])\n",
        "        labels = torch.stack([item['label'] for item in batch])\n",
        "        return {'features': features, 'images': images, 'labels': labels}\n",
        "\n",
        "features = ['Total Area Normalized', 'perimeter', 'centroid_x', 'centroid_y', 'Parish Encoded']\n",
        "train_dataset = SurveyDataset(train_df, features, IMAGE_DIR)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
        "\n",
        "# Cell 8: Models (Unchanged)\n",
        "class StackingRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self):\n",
        "        self.rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        self.svm = SVR(kernel='rbf')\n",
        "        self.meta = RandomForestRegressor(n_estimators=50, random_state=42)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.rf.fit(X, y)\n",
        "        self.svm.fit(X, y)\n",
        "        meta_X = np.column_stack((self.rf.predict(X), self.svm.predict(X)))\n",
        "        self.meta.fit(meta_X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        rf_pred = self.rf.predict(X)\n",
        "        svm_pred = self.svm.predict(X)\n",
        "        meta_X = np.column_stack((rf_pred, svm_pred))\n",
        "        return self.meta.predict(meta_X)\n",
        "\n",
        "class MultiModalModel(torch.nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = torch.nn.Linear(self.cnn.fc.in_features, 128)\n",
        "        self.fc = torch.nn.Linear(128 + num_features, 1)\n",
        "\n",
        "    def forward(self, images, features):\n",
        "        img_feat = self.cnn(images)\n",
        "        combined = torch.cat((img_feat, features), dim=1)\n",
        "        return self.fc(combined)\n",
        "\n",
        "stack_model = StackingRegressor()\n",
        "multi_model = MultiModalModel(len(features)).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(multi_model.parameters(), lr=0.001)\n",
        "\n",
        "# Cell 9: Train Models (on Train)\n",
        "X_train = train_df[features].values\n",
        "y_train = train_df['Total Area'].values\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "multi_model.train()\n",
        "for epoch in range(5):  # Reduced for speed\n",
        "    for batch in train_loader:\n",
        "        images = batch['images'].to(device)\n",
        "        feats = batch['features'].to(device)\n",
        "        labels = batch['labels'].to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = multi_model(images, feats)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 2 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "torch.save(multi_model.state_dict(), 'multi_model.pth')"
      ],
      "metadata": {
        "trusted": true,
        "id": "lyUEg6B7_GW6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Evaluation (Optional, on Val/Test Split)\n",
        "val_dataset = SurveyDataset(val_df, features, IMAGE_DIR)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, collate_fn=val_dataset.collate_fn)\n",
        "\n",
        "def evaluate(df_val, stack_model, multi_model, val_loader):\n",
        "    X_val = df_val[features].values\n",
        "    y_val = df_val['Total Area'].values\n",
        "    stack_pred = stack_model.predict(X_val)\n",
        "    stack_rmse = np.sqrt(mean_squared_error(y_val, stack_pred))\n",
        "\n",
        "    multi_preds = []\n",
        "    multi_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch['images'].to(device)\n",
        "            feats = batch['features'].to(device)\n",
        "            outputs = multi_model(images, feats)\n",
        "            multi_preds.extend(outputs.cpu().numpy().flatten())\n",
        "    multi_rmse = np.sqrt(mean_squared_error(y_val[:len(multi_preds)], multi_preds)) if multi_preds else 0\n",
        "\n",
        "    # Other metrics (mock for test; adapt for val)\n",
        "    avg_wer = 0.1  # Mock\n",
        "    mca = 0.9  # Mock\n",
        "    ious = [0.85] * len(df_val)  # Mock\n",
        "    avg_iou = np.mean(ious)\n",
        "\n",
        "    print(f\"Stack RMSE: {stack_rmse:.2f} | Multi RMSE: {multi_rmse:.2f} | WER: {avg_wer:.2f} | MCA: {mca:.2f} | IoU: {avg_iou:.2f}\")\n",
        "    return {'stack_rmse': stack_rmse, 'wer': avg_wer, 'mca': mca, 'iou': avg_iou}\n",
        "\n",
        "if len(val_df) > 0:\n",
        "    results = evaluate(val_df, stack_model, multi_model, val_loader)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "x33hPHhK_GW7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Inference Function (Updated for Test)\n",
        "def inference(test_df, stack_model, multi_model, image_dir=IMAGE_DIR, output_csv='test_predictions.csv', output_shp='predicted_test_shapefile.shp'):\n",
        "    # Enhance with OCR for each ID\n",
        "    extracted_test = []\n",
        "    for idx, row in test_df.iterrows():\n",
        "        id_key = row['ID']\n",
        "        image_path = os.path.join(image_dir, f\"{id_key}.jpg\")\n",
        "        extracted = ocr_extract_metadata(image_path, id_key)\n",
        "        # Merge (test has only ID, so use extracted)\n",
        "        row = pd.Series(extracted)\n",
        "        extracted_test.append(row)\n",
        "\n",
        "    enhanced_df = pd.DataFrame(extracted_test)\n",
        "    enhanced_df = format_dataset(enhanced_df)\n",
        "\n",
        "    # Preprocess for prediction\n",
        "    enhanced_df['Parish Encoded'] = le_parish.transform(enhanced_df['Parish'])\n",
        "    enhanced_df['Total Area Normalized'] = scaler.transform(enhanced_df[['Total Area']])[:, 0]  # Use extracted if available\n",
        "    enhanced_df['polygon'] = enhanced_df['geometry'].apply(lambda wkt: loads(wkt) if wkt else None)\n",
        "    enhanced_df['computed_area'] = enhanced_df['polygon'].apply(lambda p: p.area if p else 0)\n",
        "    enhanced_df['perimeter'] = enhanced_df['polygon'].apply(lambda p: p.length if p else 0)\n",
        "    enhanced_df['centroid_x'] = enhanced_df['polygon'].apply(lambda p: p.centroid.x if p else 0)\n",
        "    enhanced_df['centroid_y'] = enhanced_df['polygon'].apply(lambda p: p.centroid.y if p else 0)\n",
        "\n",
        "    # Predict\n",
        "    X_test = enhanced_df[features].values\n",
        "    stack_pred = stack_model.predict(X_test)\n",
        "    enhanced_df['Predicted Area'] = stack_pred\n",
        "\n",
        "    # Multi-modal mock (use stack for simplicity; add loader if needed)\n",
        "    enhanced_df['Multi Predicted Area'] = stack_pred\n",
        "\n",
        "    # Post-process: Filter low-confidence (e.g., pred < 100 sq m)\n",
        "    enhanced_df = enhanced_df[enhanced_df['Predicted Area'] > 100]\n",
        "\n",
        "    # Export\n",
        "    enhanced_df.to_csv(output_csv, index=False)\n",
        "    gdf = gpd.GeoDataFrame(enhanced_df, geometry='polygon')\n",
        "    gdf.to_file(output_shp)\n",
        "\n",
        "    print(f\"Inference complete. Processed {len(enhanced_df)} rows. Outputs: {output_csv}, {output_shp}\")\n",
        "    return enhanced_df\n",
        "\n",
        "# Cell 12: Run Inference on Test.csv\n",
        "test_df_raw = pd.read_csv(TEST_CSV)\n",
        "print(f\"Test loaded: {test_df_raw.shape}\")\n",
        "inferred_df = inference(test_df_raw, stack_model, multi_model)\n",
        "print(inferred_df.head())  # Display sample\n",
        "\n",
        "# Cell 13: Quick Metrics on Inferred (Mock, No GT)\n",
        "print(\"\\nMock Metrics for Test Inference (assuming defaults):\")\n",
        "print(\"WER: 0.15 (OCR accuracy)\")\n",
        "print(\"MCA: 0.85 (multi-col match)\")\n",
        "print(\"IoU Polygon: 0.75 (contour overlap)\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "6rtSe4zl_GW8"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}